<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv="Content-Language" content="zh-cn">
<meta name="GENERATOR" content="Microsoft FrontPage 6.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<title>PERSONAL</title>
<style>
<!--
div.Section1
	{page:Section1;}
SPAN.skype_pnh_container {
	DIRECTION: ltr !important
}
SPAN.skype_pnh_container SPAN.skype_pnh_mark {
	DISPLAY: none !important
}

SPAN.skype_pnh_container IMG.skype_pnh_logo_img {
	MARGIN-RIGHT: 5px !important
}

h3
	{margin-right:0in;
	margin-left:0in;
	font-size:13.5pt;
	font-family:"Times New Roman","serif";
	}
.style1 {font-family: "Times New Roman", Times, serif}
span.contentpasted0
	{}
span.ui-provider
	{}
-->
</style>
</head>

<body>

<p style="line-height: 150%" align="justify">
<span lang="EN-US" style="font-family: Times New Roman; font-weight: normal">
<font size="4">
&nbsp;&nbsp;&nbsp; Guoying Zhao is currently an </span>
<span lang="EN-US" style="font-family: Times New Roman; font-weight: 700">
Academy Professor</span><span lang="EN-US" style="font-family: Times New Roman; font-weight: normal">
with Academy Finland and </span>
</font><font size="4">
<span style="font-family: Times New Roman; font-weight: normal">with the Center for Machine Vision and Signal Analysis 
(CMVS), University of Oulu, Finland<span lang="en-us">, and visiting professor 
with Aalto University and Stanford University</span>. She has been a </span>
<span style="font-family: Times New Roman; font-weight: 700">full professor</span><span style="font-family: Times New Roman; font-weight: normal"> 
(tenured, from 2017) with CMVS, where she was a senior researcher (2005-2007), Academy postdoctoral 
researcher (2008-2011), </span>
<span style="font-family: Times New Roman; font-weight: 700">Academy research fellow</span><span style="font-family: Times New Roman; font-weight: normal"> (2011-2017) and Associate 
Professor (tenure track, 2014-2017). She received the Ph.D. degree in computer science from the 
Chinese Academy of Sciences, Beijing, China, in 2005.&nbsp; <span lang="en-us">
She got the Academy Postdoctoral position in 2007, </span>was selected in 2011 
to the highly competitive Academy Research Fellow position, in 2020 selected to Prestigious Academy Professor position, 
in 2022 elected to a </span>
<span style="font-family: Times New Roman; font-weight: 700">member </span>
<font face="Times New Roman"><b>of Finnish Academy of Sciences and Letter</b>s </font><span style="font-family: Times New Roman; font-weight: normal"> 
and in 2023 elected to a </span>
<span style="font-family: Times New Roman; font-weight: 700"> member of Academia 
Europaea</span><span style="font-family: Times New Roman; ">.</span><span style="font-family: Times New Roman; font-weight: normal"> She has 
authored or co-authored more than <span lang="en-us">300</span> papers in journals and conferences, and 
has served </span> </font><font size="4">
<span style="font-family: Times New Roman; font-weight: normal">as a reviewer 
for many journals and conferences. Her papers have currently over 23300 citations in Google Scholar 
(h-index 72). She is 
<span lang="en-us">t</span>utorial <span lang="en-us">c</span>hair for ICPR 
2024, panel chair for FG 2023, and publicity chair for SCIA 2023. S</span><span style="font-family: Times New Roman">he </span>
<span style="font-family: Times New Roman; font-weight: normal">was </span>
<b>
<span style="font-family: Times New Roman">general chair</span></b><span style="font-family: Times New Roman"> 
of &nbsp;Arctic AI days 2022, International Conference on Image Processing 
and Media Computing 2022 (ICIPMC 2022)</span><span style="font-family: Times New Roman; font-weight: normal"><span lang="en-us"> 
and </span>ICBEA (2019, 2020)</span><span lang="en-us" style="font-family: Times New Roman">,
</span><span style="font-family: Times New Roman; font-weight: 700">co-program chair</span><span style="font-family: Times New Roman; font-weight: normal"> of ACM International Conference on Multimodal 
Interaction 2021 (ICMI), </span>
<span style="font-family: Times New Roman; font-weight: 700">co-chair for Late Breaking 
Results</span><span style="font-family: Times New Roman; font-weight: normal"> of ICMI 
2019, </span><span style="font-family: Times New Roman; font-weight: 700">
co-publicity chair</span><span style="font-family: Times New Roman; font-weight: normal"> 
for FG 2018, has served as area chairs for several conferences and is<span lang="en-us">/was</span> </span>
<span style="font-family: Times New Roman; font-weight: 700">associate 
editor</span><span style="font-family: Times New Roman; font-weight: normal"> for Pattern Recognition, 
IEEE Trans. on Multimedia, IEEE Trans. on Circuits and Systems for 
Video Technology, Image and Vision Computing, Frontiers in Psychology, Journal 
of Electronic Imaging, and International Journal of Network Dynamics and 
Intelligence Journals. She has lectured tutorials at FG<span lang="en-us"> 2018, </span>SCIA 
2013, ICCV 2009 and ICPR 2006, and authored/edited three books and <span lang="en-us">nine</span> special issues in 
journals. Dr. Zhao was a Co-Chair of 23 International Workshops / special 
sessions in top venues, such as ICCV, 
CVPR, ECCV, ACCV and FG. Her students <span lang="en-us">and 
researchers </span>are 
frequent recipients of very prestigious and highly competitive 
<span lang="en-us">positions and </span>fellowships, such 
<span lang="en-us">as professors/associate professors/assistant professors,</span> <span lang="en-us">
Academy of Finland Research Fellow, Academy of Finland Postdoc positions, </span>the Nokia 
Scholarsh</span></font><font size="4"><span style="font-family: Times New Roman; font-weight: normal">ip, 
Endeavour Research Fellowship, Ta</span></font><span style="font-family: Times New Roman; font-weight: normal"><font size="4">uno T&ouml;nning Research funding<span lang="en-us">, 
Kauta Foundation grant</span> 
and Jorma Ollila grant. </font> </span><font size="4">
<span style="font-family: Times New Roman; font-weight: normal">She is </span>
<span style="font-family: Times New Roman; font-weight: 700">IEEE 
Fellow</span><span style="font-family: Times New Roman; font-weight: normal">, </span>
<span style="font-family: Times New Roman; font-weight: 700">IAPR Fellow</span><span style="font-family: Times New Roman; font-weight: normal"> and </span>
<span style="font-family: Times New Roman; font-weight: 700">AAIA Fellow</span><span style="font-family: Times New Roman; font-weight: normal">. 
Her current research interests include image and video representation, facial expression 
and micro-expression 
recognition, human motion analysis, remote physiological signal measure and 
multi-modal learning. Her research has 
been reported by Finnish TV programs, newspapers, Technology Discovery TV, MIT T</span></font><span style="font-family: Times New Roman; font-weight: normal"><font size="4">echnology Review, 
etc. </font> </span></p>

<table border="0" cellpadding="0" cellspacing="0" style="border-collapse: collapse" bordercolor="#111111" width="179%" id="AutoNumber1">
  <tr>
    <td width="100%">
    <table border="0" width="100%" id="table1" height="325">
		<tr>
			<td width="273"height="52" valign=top><b><font face="Times New Roman"><span lang="EN-US">
    Address:</span></font></b></td>
			<td height="52" valign=top width="1385">
			<p style="line-height: 150%"><font face="Times New Roman">
			Center for Machine 
    Vision and Signal Analysis,<br>
			P.O.Box 4500 FI-90014 University of Oulu, Finland.</font></td>
		</tr>
		<tr>
			<td width="273"height="37"><font face="Times New Roman"><b>Office:</b></font></td>
			<td height="37" width="1385">
    <p class="MsoNormal"><font face="Times New Roman">TS</font><span lang="en-us"><font face="Times New Roman">302</font></span></p>			</td>
		</tr>
		<tr>
			<td width="273"height="35"><font face="Times New Roman"><b>Phone<span lang="en-us"> 
			Number</span>:</b> </font></td>
			<td height="35" width="1385"><font face="Times New Roman">+358 
			</font><span lang="en-us"><font face="Times New Roman">294487564</font></span></td>
		</tr>
		<tr>
			<td width="273" height="32"><b><font face="Times New Roman"> E_mail:</font></b></td>
			<td height="32" width="1385">
    <p class="MsoNormal"><a href="mailto:firstname.lastname@ee.oulu.fi">
	<span lang="en-us"><font face="Times New Roman">firstname.lastname(at)</font></span><font face="Times New Roman"><span lang="en-us">oulu.fi</span></font></a></p></td>
		</tr>
		<tr>
			<td width="273" height="45"><b>
    		<font face="Times New Roman">Research 
			Interests:</font></b></td>
			<td width="1385" height="45">
    <font face="Times New Roman">Computer Vision, Pattern Recognition, Affective 
	Computing, Digital image &amp; video processing, 
    Human motion analysis, Virtual Reality, Biometrics, etc.</font></td>
		</tr>
		<tr>
			<td width="273"><b><font face="Times New Roman">
			<a target="_blank" href="http://scholar.google.fi/citations?user=hzywrFMAAAAJ">
			Google Scholar</a></font></b></td>
			<td width="1385">
    <span style="font-family: Times New Roman">
	<a target="_blank" href="http://scholar.google.fi/citations?user=hzywrFMAAAAJ">
	http://scholar.google.fi/citations?user=hzywrFMAAAAJ</a></span></td>
		</tr>
		<tr>
			<td width="273" height="5"></td>
			<td height="5" width="1385"></td>
		</tr>
	  </table>
    <p><font face="Times New Roman">
	<img border="0" src="images/bar.bmp" width="561" height="5"></font></p>
	<div style="language:fi;margin-top:5.76pt;margin-bottom:0pt;margin-left:.38in;
text-indent:-.38in;text-align:left;direction:ltr;unicode-bidi:embed;vertical-align:
baseline;mso-line-break-override:restrictions;punctuation-wrap:simple">
		<p style="margin-top: 24px; margin-bottom: 24px">
		<img border="0" src="202109_Group.jpg" width="1128" height="754"></p>
		<p style="margin-top: 24px; margin-bottom: 24px"><u><b>
		<font face="Times New Roman">NEWS:</font></b></u></p>
		<p style="margin-top: 24px; margin-bottom: 24px">
		<font face="Times New Roman"><span lang="en-us"><u>2023.04:</u> <b>Dr. Yang 
		L</b></span><b>iu</b> awarded two year grant from <b>Finnish Culture Foundation</b> (The 
		North Ostrobothnia Regional Fund) for Postdoctoral Research in the field 
		of Natural Sciences with the topic &quot;Towards Crowdsensing Facial Affect 
		Encoder for Trustworthy Mental Wellbeing: A study of Workplace Pain 
		Detection&quot;. </font></p>
		<p style="margin-top: 24px; margin-bottom: 24px"><span lang="en-us"><u>
		<font face="Times New Roman">2023.03:</font></u></span><font face="Times New Roman"><span lang="en-us"> 
		Call for participation and submissions: </span>
		<a href="https://cv-ac.github.io/MiGA2023/">1st&nbsp;Workshop &amp; Challenge on 
		Micro-gesture Analysis for Hidden Emotion understanding (MiGA)</a>
		<span lang="en-us">with <a target="_blank" href="https://ijcai-23.org/">
		IJCAI 2023</a>. </span></font></p>
		<p style="margin-top: 24px; margin-bottom: 24px">
		<font face="Times New Roman">2021.06: Muzammil recently won the Tauno 
		T&ouml;nning Foundation Grant.</font></p>
		<p style="margin-top: 24px; margin-bottom: 24px"><span lang="en-us">
		<font face="Times New Roman">2021.03: </font></span>
		<font face="Times New Roman"><b>The 2nd Multimodal Sentiment Analysis 
		Challenge</b>: <a href="https://www.muse-challenge.org/muse2021">
		https://www.muse-challenge.org/muse2021</a>, with ACM MM<span lang="en-us"> 
		2021</span>. <span lang="en-us">Welcome to participate!</span></font></p>
		<p style="margin-top: 24px; margin-bottom: 24px">
		<font face="Times New Roman">2021.03: IEEE Finland Section best student 
		conference paper award 2020, for our ICCV 2019 paper &quot;Zitong Yu, Wei Peng, Xiaobai Li, Xiaopeng Hong, Guoying Zhao. Remote 
Heart Rate Measurement from Highly Compressed Facial Videos: an End-to-end Deep 
Learning Solution with Video Enhancement. ICCV 2019.&quot;</font></p>
		<p>
		<font face="Times New Roman">2020.10: Mr. Muzammil Behzad won the three minutes PhD thesis 
		competition organized by ICIP2020:
		<a href="https://2020.ieeeicip.org/3-minute-thesis-competition/">
		https://2020.ieeeicip.org/3-minute-thesis-competition/</a>.</font><p>
		<font face="Times New Roman">
		2020.08: We have got the 2nd Place on Action Recognition Track of ECCV 
		2020 VIPriors Challenges (with accuracy of 88.31%). More details can be 
		found
		<a target="_blank" href="https://competitions.codalab.org/competitions/23706#results">
		here</a><span lang="en-us">.</span></font><p>
		<font face="Times New Roman">
		2020.08: Dr. Xiaobai Li has been selected to Assistant Professor (Tenure 
		Track) position in CMVS, University of Oulu.</font><p>
		<font face="Times New Roman">
		2020.07: Dr. Jingang Shi has been appointed Associate Professor position 
		in Xi'an Jiaotong University, China.</font></div>
		<p><span lang="EN-US" style="font-family: Times New Roman">2020.06: 
	We have won the <b>first place</b> in the <b>ChaLearn multi-modal face 
	anti-spoofing attack detection challenge</b> @ CVPR 2020, and the <b>second 
	place </b>in the <b>ChaLearn single-modal face anti-spoofing attack 
	detection challenge</b> @CVPR 2020. More details:
	<a style="color: #0563C1; text-decoration: underline; text-underline: single" href="https://sites.google.com/qq.com/face-anti-spoofing/winners-results/challengecvpr2020">
	https://sites.google.com/qq.com/face-anti-spoofing/winners-results/challengecvpr2020</a>.</span></p>
	<p>
		<font face="Times New Roman">
		2020.06: Joint work with Learning &amp; Educational Technology Research Unit 
	(LET) accepted to top tier IEEE Transactions on Affective Computing: &quot;Muhterem 
	Dindar, Sanna J&auml;rvel&auml;, Sara Ahola, Xiaohua Huang, Guoying Zhao. <b>Leaders 
	and followers identified by emotional mimicry during collaborative learning: 
	A facial expression recognition study on emotional valence</b>.&quot;</font></p>
	<p>
		<font face="Times New Roman">
		2020.06: Ms. Yingyue Xu has successfully defended her doctoral 
	dissertation and obtained PhD degree.</font></p>
	<p>
		<font face="Times New Roman">
		2020.05: Dr. Xin Liu has been selected to highly competitive Academy of 
	Finland postdoctoral position 2020.09-2023.08.</font></p>
	<p style="margin-top: 24px; margin-bottom: 24px"><b><u><font face="Times New Roman">
	<span lang="en-us">Downloading: Databases:</span></font></u></b></p>
	<p><span style="font-family: Times New Roman; font-weight:700" lang="en-us">
	Databases:</span></p>
	<ul>
		<li><span style="font-family: Times New Roman" lang="en-us"><b>OuluVS 
		database</b>: </span>
		<span style="font-size: 12.0pt; font-family: 'Times New Roman',serif">It 
		includes the video and audio data for 20 subjects uttering ten 
		phrases:&nbsp;Hello, Excuse me, I am sorry, Thank you, Good bye, See you, 
		Nice to meet&nbsp;you, You are welcome, How are you, Have a good time. Each 
		person&nbsp;spoke each&nbsp;phrase five times.&nbsp;There are also videos with head 
		motion from front to left, from&nbsp;front to right, without utterance, five 
		times for each person. </span>
		<span lang="en-us" style="font-size: 12.0pt; font-family: 'Times New Roman',serif">
		The details and the baseline results for visual speech recognition can 
		be found in:</span></li>
	</ul>
	<p class="MsoNormal"><span style="font-family: Times New Roman">Zhao G, 
	Barnard M &amp; Pietik&auml;inen M (2009). Lipreading with local spatiotemporal 
	descriptors. IEEE Transactions on Multimedia 11(7):1254-1265.</span></p>
	<p class="MsoNormal">
	<span style="font-size: 12.0pt; font-family: 'Times New Roman',serif">The 
	database can be used, for example,&nbsp; in studying the visual speech 
	recognition (lipreading).<span style="font-family: Times New Roman,serif; font-size:12.0pt"><span lang="en-us">
	</span>If yo</span></span><span style="font-family: Times New Roman" lang="en-us">u 
	want to get a copy, please contact
	<a href="mailto:firstname.lastname@oulu.fi">me</a>.</span></p>
	<ul>
		<li>
		<p class="MsoNormal">
		<span style="font-family: Times New Roman" lang="en-us"><b>Oulu-CASIA 
		NIR&amp;VIS facial expression database</b>: </span>
		<span style="font-size: 12.0pt; font-family: 'Times New Roman',serif">It 
		contains videos with the six typical expressions&nbsp; (happiness, 
		sadness, surprise, <br>anger, fear, disgust) from 80 subjects captured 
		with two imaging systems, NIR (Near Infrared) and VIS (Visible light), 
		under three different<span lang="en-us">
		</span>illumination conditions: normal indoor illumination, weak 
		illumination (only computer display is on) and dark illumination (all 
		lights are off).<span lang="en-us"> </span>The database can be used, for 
		example,&nbsp; in studying the effects of illumination variations<span lang="en-us"> </span>
		to facial expressions, cross-imaging-system facial expression 
		recognition or face recognition.</span></p>
		</li>
	</ul>
	<p class="MsoNormal">
	<span style="font-family: Times New Roman" lang="en-us">This database has 
	been released. If you are interested, please contact
	<a href="mailto:firstname.lastname@oulu.fi">me</a>.</span></p>
	<div dir="ltr" id="page" lang="en">
		<div dir="ltr" id="content" lang="en">
			<ul>
				<li>
				<p class="line891"><b>
				<span style="font-family: Times New Roman">
				<a href="http://www.cse.oulu.fi/SPOSDatabase">SPOS database</a>				</span></b>
				<span style="font-size: 12.0pt; font-family: 'Times New Roman',serif">
				- spontaneous and posed facial expressions database </span>
				<span id="line-35" class="anchor"></span></li>
			</ul>
			<span id="bottom" class="anchor"></span></div>
	</div>
	<div dir="ltr" id="page0" lang="en">
		<div dir="ltr" id="content0" lang="en">
			<p class="line862"><span style="font-family: Times New Roman">SPOS 
			database includes spontaneous and posed facial expressions of 7 
			subjects. Emotional movie clips were shown to subjects to induce 
			spontaneous facial expressions, which include six categories of 
			basic emotions (happy, sad, anger, surprise, fear disgust). Subjects 
			were also asked to pose the six kinds of facial expressions after 
			watching movie clips. Data are recorded by both visual and near 
			infer-red camera. All together 84 posed and 147 spontaneous facial 
			expression clips were labeled out from the starting point to the 
			apex. </span></p>
			<p class="line874"><span style="font-family: Times New Roman">So 
			far, spontaneous and posed facial expressions are usually found in 
			different databases. The difference between databases (different 
			experimental setting and different participants) hindered researches 
			which considered both spontaneous and posed facial expressions. This 
			database offers data collected on the same participants and under 
			the same recording condition, which can be used for comparing or 
			distinguishing spontaneous and posed facial expressions</span></div>
	</div></td>
  </tr>
  </table>


</body>

</html>