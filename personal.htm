<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv="Content-Language" content="zh-cn">
<meta name="GENERATOR" content="Microsoft FrontPage 6.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<title>PERSONAL</title>
<style>
<!--
div.Section1
	{page:Section1;}
SPAN.skype_pnh_container {
	DIRECTION: ltr !important
}
SPAN.skype_pnh_container SPAN.skype_pnh_mark {
	DISPLAY: none !important
}

SPAN.skype_pnh_container IMG.skype_pnh_logo_img {
	MARGIN-RIGHT: 5px !important
}

h3
	{margin-right:0in;
	margin-left:0in;
	font-size:13.5pt;
	font-family:"Times New Roman","serif";
	}
.style1 {font-family: "Times New Roman", Times, serif}
-->
</style>
</head>

<body>

<p style="line-height: 150%" align="justify">
<span lang="EN-US" style="font-family: Times New Roman; font-weight: normal">
<font size="4">
&nbsp;&nbsp;&nbsp; Guoying Zhao is currently a P</font></span><span style="font-family: Times New Roman; font-weight: normal"><font size="4">rofessor 
with the Center for Machine Vision and Signal Analysis, University of Oulu, 
Finland, where she has been a senior researcher since 2005 and an Associate 
Professor since 2014. She received the Ph.D. degree in computer science from the 
Chinese Academy of Sciences, Beijing, China, in 2005.&nbsp; <span lang="en-us">
She got the Academy Postdoctoral position in 2007, and i</span>n 2011, she was 
selected to the highly competitive Academy Research Fellow position. She has 
authored or co-authored more than <span lang="en-us">23</span>0 papers in journals and conferences, and 
has served </font></span><font size="4">
<span style="font-family: Times New Roman; font-weight: normal">as a reviewer for many journals and conferences. Her papers have 
currently over 12500 citations in Google Scholar (h-index 
52). She is Co-Program chair of ACM International Conference on Multimodal 
Interaction 2021 (ICMI), Special 
Sessions/Panels Chairs for FG 2023, and general chair for ICBEA 2020. She was general chair for ICBEA 2019, Co-Chair for Late Breaking 
Results of ICMI 2019, co-publicity c</span></font><span style="font-family: Times New Roman; font-weight: normal"><font size="4">hair 
for FG 2018, has served as area chairs for several conferences and is associate 
editor for Pattern Recognition, IEEE Transactions on Circuits and Systems for 
Video Technology, and Image and Vision Computing Journals.</font></span><span lang="EN-US" style="font-size: 12.0pt; line-height: 115%; font-family: Arial,sans-serif">
</span><span style="font-family: Times New Roman; font-weight: normal">
<font size="4">She has lectured tutorials at <span lang="en-us">FG 2018, </span>ICPR 2006, ICCV 2009, 
and SCIA 2013, and authored/edited three books and <span lang="en-us">eight</span> special issues in 
journals. Dr. Zhao was a Co-Chair of 17 International Workshops / special 
sessions in top venues, such as ICCV, 
CVPR, ECCV, ACCV and FG. Her students <span lang="en-us">and 
researchers </span>are 
frequent recipients of very prestigious and highly competitive f</font></span><span style="font-family: Times New Roman; font-weight: normal"><font size="4">ellowships, such 
as <span lang="en-us">Academy of Finland Postdoc position, </span>the Nokia 
Scholarsh</font></span><font size="4"><span style="font-family: Times New Roman; font-weight: normal">ip, 
Endeavour Research Fellowship, Ta</span></font><span style="font-family: Times New Roman; font-weight: normal"><font size="4">uno T&ouml;nning Research funding<span lang="en-us">, 
Kauta Foundation grant</span> 
and Jorma Ollila grant. </font> </span><font size="4">
<span style="font-family: Times New Roman; font-weight: normal">She is IEEE 
Senior Member. Her current research interests include image and video 
descriptors, gait analysis, dynamic-texture recognition, facial-expression 
recognition, human motion analysis, and person identification. Her research has 
been reported by Finnish TV programs, newspapers and MIT Technology Review.</span></font></p>

<table border="0" cellpadding="0" cellspacing="0" style="border-collapse: collapse" bordercolor="#111111" width="100%" id="AutoNumber1">
  <tr>
    <td width="100%">
    <table border="0" width="100%" id="table1" height="325">
		<tr>
			<td width="115" height="39"><font face="Times New Roman"><b>Nationality:</b></font></td>
			<td height="39" width="416"><font face="Times New Roman"><span lang="en-us">
			P.R.China</span></font></td>
		</tr>
		<tr>
			<td width="115"height="52" valign=top><b><font face="Times New Roman"><span lang="EN-US">
    Address:</span></font></b></td>
			<td height="52" valign=top width="416">
			<p style="line-height: 150%"><font face="Times New Roman">
			Center for Machine 
    Vision and Signal Analysis,<br>
			P.O.Box 4500 FI-90014 University of Oulu, Finland.</font></td>
		</tr>
		<tr>
			<td width="115"height="37"><font face="Times New Roman"><b>Office:</b></font></td>
			<td height="37" width="416">
    <p class="MsoNormal"><font face="Times New Roman">TS</font><span lang="en-us"><font face="Times New Roman">302</font></span></p>			</td>
		</tr>
		<tr>
			<td width="115"height="35"><font face="Times New Roman"><b>Phone<span lang="en-us"> 
			Number</span>:</b> </font></td>
			<td height="35" width="416"><font face="Times New Roman">+358 
			</font><span lang="en-us"><font face="Times New Roman">294487564</font></span></td>
		</tr>
		<tr>
			<td width="115" height="32"><b><font face="Times New Roman"> E_mail:</font></b></td>
			<td height="32" width="416">
    <p class="MsoNormal"><a href="mailto:firstname.lastname@ee.oulu.fi">
	<span lang="en-us"><font face="Times New Roman">firstname.lastname(at)</font></span><font face="Times New Roman"><span lang="en-us">oulu.fi</span></font></a></p></td>
		</tr>
		<tr>
			<td width="115"valign=top height="67"><b>
    		<font face="Times New Roman"><a target="_blank" href="Research.htm">Research 
			</a>Interest<span lang="en-us">s</span>: </font></b></td>
			<td width="416"valign=top height="67">
    <span lang="EN-US" style="font-family: Times New Roman">
    Computer Vision, Pattern Recognition, Digital image &amp; video processing, 
    Human motion analysis, Virtual Reality, Computer Graphics, Biometrics, 
    Surveillance, etc.</span></td>
		</tr>
		<tr>
			<td width="115"><b><font face="Times New Roman">
			<a target="_blank" href="http://scholar.google.fi/citations?user=hzywrFMAAAAJ">
			Google Scholar</a></font></b></td>
			<td width="416">
    <span style="font-family: Times New Roman">
	<a target="_blank" href="http://scholar.google.fi/citations?user=hzywrFMAAAAJ">
	http://scholar.google.fi/citations?user=hzywrFMAAAAJ</a></span></td>
		</tr>
		<tr>
			<td width="115" height="5"></td>
			<td height="5" width="416"></td>
		</tr>
	  </table>
    <p><font face="Times New Roman">
	<img border="0" src="images/bar.bmp" width="561" height="5"></font></p>
	<div style="language:fi;margin-top:5.76pt;margin-bottom:0pt;margin-left:.38in;
text-indent:-.38in;text-align:left;direction:ltr;unicode-bidi:embed;vertical-align:
baseline;mso-line-break-override:restrictions;punctuation-wrap:simple">
		<font face="Times New Roman">
		<u><b>Open positions</b></u>: Postdoctoral researchers, PhD students, Master thesis 
		workers.</font><p>
		<font face="Times New Roman">
		2020.10: Mr. Muzammil Behzad won the three minutes PhD thesis 
		competition organized by ICIP2020:</font><span lang="EN-US" style="font-family: Times New Roman; color: #1F497D">
		<a style="color: blue; text-decoration: underline; text-underline: single" href="https://2020.ieeeicip.org/3-minute-thesis-competition/">
		https://2020.ieeeicip.org/3-minute-thesis-competition/</a>.</span><p>
		<font face="Times New Roman">
		2020.08: We have got the 2nd Place on Action Recognition Track of ECCV 
		2020 VIPriors Challenges (with accuracy of 88.31%). More details can be 
		found
		<a target="_blank" href="https://competitions.codalab.org/competitions/23706#results">
		here</a><span lang="en-us">.</span></font><p>
		<font face="Times New Roman">
		2020.08: Dr. Xiaobai Li has been selected to Assistant Professor (Tenure 
		Track) position in CMVS, University of Oulu.</font><p>
		<font face="Times New Roman">
		2020.07: Dr. Jingang Shi has been appointed Associate Professor position 
		in Xi'an Jiaotong University, China.</font></div>
		<p><span lang="EN-US" style="font-family: Times New Roman">2020.06: 
	We have won the <b>first place</b> in the <b>ChaLearn multi-modal face 
	anti-spoofing attack detection challenge</b> @ CVPR 2020, and the <b>second 
	place </b>in the <b>ChaLearn single-modal face anti-spoofing attack 
	detection challenge</b> @CVPR 2020. More details:
	<a style="color: #0563C1; text-decoration: underline; text-underline: single" href="https://sites.google.com/qq.com/face-anti-spoofing/winners-results/challengecvpr2020">
	https://sites.google.com/qq.com/face-anti-spoofing/winners-results/challengecvpr2020</a>.</span></p>
	<p>
		<font face="Times New Roman">
		2020.06: Joint work with Learning &amp; Educational Technology Research Unit 
	(LET) accepted to top tier IEEE Transactions on Affective Computing: &quot;Muhterem 
	Dindar, Sanna J&auml;rvel&auml;, Sara Ahola, Xiaohua Huang, Guoying Zhao. <b>Leaders 
	and followers identified by emotional mimicry during collaborative learning: 
	A facial expression recognition study on emotional valence</b>.&quot;</font></p>
	<p>
		<font face="Times New Roman">
		2020.06: Ms. Yingyue Xu has successfully defended her doctoral 
	dissertation and obtained PhD degree.</font></p>
	<p>
		<font face="Times New Roman">
		2020.05: Dr. Xin Liu has been selected to highly competitive Academy of 
	Finland postdoctoral position 2020.09-2023.08.</font></p>
	<p><b><u><font face="Times New Roman">
	<span lang="en-us">Downloading: 
	codes and databases:</span></font></u></b></p>
	<p>
	<span lang="en-us" style="font-family: Times New Roman; font-weight: 700">Codes:	</span>	</p>
	<ul>
	  <li class="style1">
	    <p style="line-height: 150%; margin-bottom: 0">
		<font face="Times New Roman">
		<a href="Download/Codes/Fast_LBPTOP_Code.zip">Fast LBP-TOP</a>: Xiaopeng 
		Hong, Yingyue Xu and Guoying Zhao. LBP-TOP: a Tensor Unfolding Revisit. 
		ACCV Workshop on Spontaneous Facial Behavior Analysis &nbsp;(SFBA2), 2016.</font></p>
	    </li>
		<li class="style1">
	    <p style="line-height: 150%; margin-bottom: 0">
		<font face="Times New Roman">Implementation of <i>Hierarchical Contour Closure based Holistic Salient Object  Detection
		</i>: <a href="https://sites.google.com/view/hcchsal" target="_blank">https://sites.google.com/view/hcchsal.</a></font></p>
	    </li>
	  <li class="style1">
		<p style="line-height: 150%; margin-bottom: 0">
		<font face="Times New Roman">Implementation of <i>Side-output Residual Network for Object Symmetry Detection in  the Wild</i>: <a href="https://github.com/KevinKecc/SRN" target="_blank">https://github.com/KevinKecc/SRN</a>.</font></li>
	</ul>
	<ul>
      <li>
        <p style="line-height:150%; margin-bottom:0"> 
		<font face="Times New Roman"><a href="Download/Codes/STLBP_VC.zip">C++ implementation of spatio-temporal LBP</a></font></p>
      </li>
	  <li>
		<p style="line-height: 150%; margin-bottom: 0"> 
		<font face="Times New Roman"><a href="Download/Codes/STLBP_Matlab.rar">Matlab implementation of 
	    spatio-temporal LBP</a></font></li>
	  </ul>
	<ul>
	  <p style="margin-bottom: 0; line-height:150%">
	    <font face="Times New Roman">Publication: Zhao 
	      G &amp; Pietik&auml;inen M (2007)
	      <a class="http" href="http://www.ee.oulu.fi/research/imag/publications/publications.php?ID=740&bibtex">
          Dynamic texture recognition using local binary patterns with an 
          application to facial expressions</a>. IEEE Transactions on Pattern 
        Analysis and Machine Intelligence, 29(6):915-928. </font>    
	  </ul>
	<ul><li>
		<p style="margin-bottom: 0"><font face="Times New Roman">Implementation of Discriminative 
		Features for Matlab:<span lang="en-us"> </span>
		<a class="attachment" title href="http://www.cse.oulu.fi/CMV/Downloads/LBPMatlab?action=AttachFile&do=view&target=disCLBP.zip">disCLBP.zip</a></font></li>
	</ul>
	<div dir="ltr" id="page1" lang="en">
		<div dir="ltr" id="content1" lang="en">
			<p style="margin-top: 10px; margin-bottom: 10px">
			<font face="Times New Roman">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
			Publication: Guo Y, Zhao G &amp; Pietik&auml;inen M (2012)
			<a class="http" href="http://www.ee.oulu.fi/research/imag/publications/publications.php?ID=1642&bibtex">
			Discriminative features for texture description.</a> Pattern 
			Recognition, vol. 45, no. 10, pp. 3834-3843, 2012. </font>
			<span id="line-48" class="anchor"></span>
			<span id="line-49" class="anchor"></span>
			<span id="line-50" class="anchor"></span></div>
	</div>
	<ul>
		<li>
		<p style="margin-bottom: 0"><span lang="en-us">
		<font face="Times New Roman">Implementation of rotation invariant image 
		descriptor: <a href="Download/Codes/LBPHF_S_M.zip">concatenation of sign 
		and magnitude LBP histogram Fourier</a></font></span></li>
	</ul>
	<p style="margin-top: 0px; margin-bottom: 10px">
	<font face="Times New Roman"><span lang="en-us">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</span>Publication<span lang="en-us">: </span>Zhao G, Ahonen T, Matas J &amp; 
	Pietik&auml;inen M (2012)
	<a href="http://www.ee.oulu.fi/research/imag/publications/publications.php?ID=1599&bibtex">
	Rotation-invariant image and video description with local binary pattern 
	features.</a> IEEE Transactions on Image Processing, 21(4):1465-1467.</font></p>
	<span class="anchor" id="line-60"></span>
	<ul>
		<li>
		<p style="margin-bottom: 0"><font face="Times New Roman">Implementation 
		of temporal interpolation model using graph embedding for Matlab:
		<a href="Download/Codes/TIM_Lipreading_CVPR2011.zip">TIM_Lipreading_CVPR2011.zip</a></font></li>
	</ul>
	<p class="line867"><font face="Times New Roman"><span lang="en-us">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</span>Publications<span lang="en-us">:</span> </font>
	<span class="anchor" id="line-65"></span><font face="Times New Roman">Zhou 
	Z, Zhao G &amp; Pietik&auml;inen M (2011)
	<a class="http" href="http://www.ee.oulu.fi/research/imag/publications/publications.php?ID=1545&bibtex">
	Towards a practical lipreading system.</a> Proc. IEEE Conference on Computer 
	Vision and Pattern Recognition (CVPR 2011), 137-144. </font>&nbsp;</p>
	<ul>
		<li>
		<p style="margin-bottom: 0"><font face="Times New Roman">Implementation 
		of
		<a href="Download/Codes/ziheng_tpami_visual_speech_representation_code.zip">A Compact Representation of Visual Speech Data<span lang="en-us"> </span>
		Using Latent Variables<span lang="en-us"> for Matlab</span></a><span lang="en-us"> 
		(a bug corrected - Sep. 24, 2014).</span></font></li>
	</ul>
	<p class="line867"><span lang="en-us">&nbsp;&nbsp; </span><font face="Times New Roman">
	Publication<span lang="en-us">: </span> </font><a name="OLE_LINK46">
	<font face="Times New Roman">Zhou<span lang="en-us"> Z</span>,  
Hong<span lang="en-us"> X</span>, Zhao<span lang="en-us"> G</span>, and Pietik&auml;inen<span lang="en-us"> 
	M</span> <span lang="en-us">(2013)</span> A Compact Representation of Visual 
	Speech Data Using Latent Variables. TPAMI<span lang="en-us">.</span></font></a></p>
	<p><span style="font-family: Times New Roman; font-weight:700" lang="en-us">Databases:</span></p>
	<ul>
		<li><span style="font-family: Times New Roman" lang="en-us"><b>OuluVS 
	database</b>: </span>
		<span style="font-size: 12.0pt; font-family: 'Times New Roman',serif">It 
	includes the video and audio data for 20 subjects uttering ten 
	phrases:&nbsp;Hello, Excuse me, I am sorry, Thank you, Good bye, See you, Nice to 
	meet&nbsp;you, You are welcome, How are you, Have a good time. Each person&nbsp;spoke 
	each&nbsp;phrase five times.&nbsp;There are also videos with head motion from front to 
	left, from&nbsp;front to right, without utterance, five times for each person. He</span><span lang="en-us" style="font-size: 12.0pt; font-family: 'Times New Roman',serif">re is the
		<a href="Download/Databases/OuluVS/Data%20collection%20report%20for%20lip%20movement_distribution.pdf">document</a> for the collection information. The details and the baseline 
	results for visual speech recognition can be found in: </span></li>
	</ul>
	<p class="MsoNormal"><span style="font-family: Times New Roman">Zhao G, 
	Barnard M &amp; Pietik&auml;inen M (2009).
	<a href="Download/Databases/OuluVS/lipreading-final-DC.pdf">Lipreading with 
	local spatiotemporal descriptors.</a> IEEE Transactions on Multimedia 
	11(7):1254-1265.</span></p>
	<p class="MsoNormal">
	<span style="font-size: 12.0pt; font-family: 'Times New Roman',serif">The 
	database can be used, for example,&nbsp; in studying the visual speech 
	recognition (lipreading).<span style="font-family: Times New Roman,serif; font-size:12.0pt"><span lang="en-us">
	</span>If 
	yo</span></span><span style="font-family: Times New Roman" lang="en-us">u 
	want to get this database, please contact <a href="mailto:firstname.lastname@ee.oulu.fi">me</a>.</span></p>
	<ul>
		<li>
		<p class="MsoNormal">
		<span style="font-family: Times New Roman" lang="en-us"><b>Oulu-CASIA NIR&amp;VIS 
	facial expression database</b>: </span>
		<span style="font-size: 12.0pt; font-family: 'Times New Roman',serif">It 
	contains videos with the six typical expressions&nbsp; (happiness, sadness, 
	surprise, <br>anger, fear, disgust) from 80 subjects captured with two imaging systems, 
	NIR (Near Infrared) and VIS (Visible light), under three different<span lang="en-us">
		</span>illumination conditions: normal indoor illumination, weak 
	illumination (only computer display is on) and dark illumination (all lights 
	are off).<span lang="en-us"> </span></span>
		<span lang="en-us" style="font-size: 12.0pt; font-family: 'Times New Roman',serif">Here is the
		<a href="Download/Databases/NIR_VL_FED/Description.pdf">document</a> for 
	database description. </span>
		<span style="font-size: 12.0pt; font-family: 'Times New Roman',serif">The 
	database can be used, for example,&nbsp; in studying the effects of illumination 
	variations<span lang="en-us"> </span>to facial expressions, 
	cross-imaging-system facial expression recognition or face recognition.</span></p>
		</li>
	</ul>
	<p class="MsoNormal">
	<span style="font-family: Times New Roman" lang="en-us">This database now is released. If you are interested, please contact
	<a href="mailto:firstname.lastname@ee.oulu.fi">me</a>.</span></p>
	<div dir="ltr" id="page" lang="en">
		<div dir="ltr" id="content" lang="en">
			<ul>
				<li>
				<p class="line891"><b>
				<span style="font-family: Times New Roman">
				<a href="http://www.cse.oulu.fi/SPOSDatabase">SPOS database</a>				</span></b>
				<span style="font-size: 12.0pt; font-family: 'Times New Roman',serif">
				- spontaneous and posed facial expressions database </span>
				<span id="line-35" class="anchor"></span></li>
			</ul>
			<span id="bottom" class="anchor"></span></div>
	</div>
	<div dir="ltr" id="page0" lang="en">
		<div dir="ltr" id="content0" lang="en">
			<p class="line862"><span style="font-family: Times New Roman">SPOS 
			database includes spontaneous and posed facial expressions of 7 
			subjects. Emotional movie clips were shown to subjects to induce 
			spontaneous facial expressions, which include six categories of 
			basic emotions (happy, sad, anger, surprise, fear disgust). Subjects 
			were also asked to pose the six kinds of facial expressions after 
			watching movie clips. Data are recorded by both visual and near 
			infer-red camera. All together 84 posed and 147 spontaneous facial 
			expression clips were labeled out from the starting point to the 
			apex. For more details about the database please see the
			<a class="attachment" title="description file" href="http://www.cse.oulu.fi/SPOSDatabase?action=AttachFile&do=view&target=SPOS+database+description+file.docx">
			description file</a>. </span><span id="line-6" class="anchor">
			</span><span id="line-7" class="anchor"></span></p>
			<p class="line874"><span style="font-family: Times New Roman">So 
			far, spontaneous and posed facial expressions are usually found in 
			different databases. The difference between databases (different 
			experimental setting and different participants) hindered researches 
			which considered both spontaneous and posed facial expressions. This 
			database offers data collected on the same participants and under 
			the same recording condition, which can be used for comparing or 
			distinguishing spontaneous and posed facial expressions</span></div>
	</div></td>
  </tr>
  </table>


</body>

</html>